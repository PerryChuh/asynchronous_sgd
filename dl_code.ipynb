{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4f45cab",
   "metadata": {},
   "source": [
    "# Start Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df16147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import psutil\n",
    "import ray\n",
    "import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", font_scale=1.2, palette=sns.color_palette(\"bright\"), color_codes=False)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'DejaVu Sans'\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "matplotlib.rcParams['figure.figsize'] = (9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d37b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(42) #主种子\n",
    "max_seed = 424242 # worker 随机种子序列范围\n",
    "n_data = 10000\n",
    "dim = 400\n",
    "batch_size = 256\n",
    "noise_scale = 1e-1\n",
    "\n",
    "iterations = 800\n",
    "num_workers = 32\n",
    "it_check = 32\n",
    "\n",
    "print(psutil.cpu_count(logical=True)) # Number of logical CPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f39bb8",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = rng.uniform(size=(n_data, dim)) / np.sqrt(dim)\n",
    "# x_rand = rng.normal(size=dim)\n",
    "# b = A @ x_rand + noise_scale * rng.normal(size=n_data)# baseline\n",
    "\n",
    "\n",
    "# def batch_grad_func(rng, x, batch_size):\n",
    "#     idx = rng.choice(n_data, size=batch_size, replace=False)\n",
    "#     return (A[idx]@x - b[idx]) @ A[idx] / batch_size\n",
    "\n",
    "# def evaluate(x):\n",
    "#     assert len(x) == dim\n",
    "#     return 0.5 * np.mean((A @ x - b)**2)\n",
    "\n",
    "# def run_single_worker_sgd(lr, iterations, batch_size, it_check):\n",
    "#     \"\"\"\n",
    "#     Runs a single-worker (pure) minibatch SGD.\n",
    "#     \"\"\"\n",
    "#     rng = np.random.default_rng(42)\n",
    "#     x = np.zeros(dim)\n",
    "    \n",
    "#     trace = []\n",
    "#     its = []\n",
    "#     ts = []\n",
    "#     t0 = time.perf_counter()\n",
    "    \n",
    "#     for it in range(iterations):\n",
    "#         # Calculate gradient on a large batch\n",
    "#         grad = batch_grad_func(rng, x, batch_size)\n",
    "        \n",
    "#         # Update model\n",
    "#         x -= lr * grad\n",
    "        \n",
    "#         if it % it_check == 0:\n",
    "#             trace.append(x.copy())\n",
    "#             its.append(it)\n",
    "#             ts.append(time.perf_counter() - t0)\n",
    "            \n",
    "#     return np.asarray(its), np.asarray(ts), np.asarray([evaluate(x) for x in trace])\n",
    "\n",
    "# x_opt, _, _, _ = np.linalg.lstsq(A, b)\n",
    "# f_min = evaluate(x_opt)\n",
    "\n",
    "# iterations_single = iterations * num_workers\n",
    "\n",
    "# its_single, ts_single, losses_single = run_single_worker_sgd(\n",
    "#     lr=0.43,\n",
    "#     iterations=iterations_single,\n",
    "#     it_check=it_check,\n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "# plt.plot(its_single, losses_single - f_min, label='Minibatch SGD')\n",
    "# plt.yscale('log')\n",
    "# plt.legend()\n",
    "# plt.xlabel('Number of gradients')\n",
    "# plt.ylabel(r'$log(F(\\mathbf{x}) - F^*)$')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dae0ff",
   "metadata": {},
   "source": [
    "# Parameters & Algorithm Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc5815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = torch.from_numpy(rng.uniform(size=(n_data, dim)) / np.sqrt(dim)).float()\n",
    "# x_rand = torch.from_numpy(rng.normal(size=dim)).float()\n",
    "# b = A @ x_rand + noise_scale * torch.from_numpy(rng.normal(size=n_data)).float()\n",
    "# b = b.reshape(n_data, 1)\n",
    "\n",
    "A = torch.rand(n_data, dim) / np.sqrt(dim)\n",
    "x_rand = torch.randn(dim, 1)\n",
    "b = A @ x_rand + noise_scale * torch.randn(n_data, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf23034f",
   "metadata": {},
   "source": [
    "## Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c43844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_objective(A_in, b_in, x):\n",
    "    return 0.5 * torch.mean((A_in @ x - b_in)**2)\n",
    "\n",
    "def evaluate(x):\n",
    "    assert len(x) == dim\n",
    "    return least_squares_objective(A, b, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_opt_np, _, _, _ = np.linalg.lstsq(A.numpy(), b.numpy())\n",
    "x_opt = torch.from_numpy(x_opt_np).float()\n",
    "f_min = evaluate(x_opt)\n",
    "print(f\"Optimal value: {f_min:.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed04c880",
   "metadata": {},
   "source": [
    "# Classical Distributed Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad132914",
   "metadata": {},
   "source": [
    "## Minibatch-SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59887c6",
   "metadata": {},
   "source": [
    "### Torch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10445abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_worker_sgd(objective_fn, A, b, lr, iterations, batch_size, seed=42):\n",
    "    \"\"\"\n",
    "    Runs a single-worker (pure) minibatch SGD for comparison.\n",
    "    This is a non-distributed, standard implementation using PyTorch.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    x = torch.zeros(dim, 1, requires_grad=True)\n",
    "    \n",
    "    trace = []\n",
    "    its = []\n",
    "    ts = []\n",
    "    \n",
    "    # Lists to store timings\n",
    "    comp_times = []\n",
    "    update_times = []\n",
    "    \n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        # Gradient zeroing\n",
    "        x.grad= None\n",
    "\n",
    "        # Sample a minibatch\n",
    "        idx = rng.choice(A.shape[0], size=batch_size, replace=False)\n",
    "        \n",
    "        # Calculate gradient on the minibatch\n",
    "        t_comp_start = time.perf_counter()\n",
    "        loss = objective_fn(A[idx], b[idx], x)\n",
    "        loss.backward()\n",
    "        grad = x.grad\n",
    "        t_comp_end = time.perf_counter()\n",
    "        comp_times.append(t_comp_end - t_comp_start)\n",
    "        \n",
    "        # Update model without tracking this operation in the graph\n",
    "        t_update_start = time.perf_counter()\n",
    "        with torch.no_grad():\n",
    "            x -= lr * grad\n",
    "        t_update_end = time.perf_counter()\n",
    "        update_times.append(t_update_end - t_update_start)\n",
    "        \n",
    "        if it % it_check == 0:\n",
    "            trace.append(x.clone().detach())\n",
    "            its.append(it)\n",
    "            ts.append(time.perf_counter() - t0)\n",
    "            \n",
    "    print(f\"Single-worker SGD Stats:\")\n",
    "    print(f\"  Gradient Computation: Mean = {np.mean(comp_times):.6f} s, Var = {np.var(comp_times):.6e} s^2\")\n",
    "    print(f\"  Parameter Update:     Mean = {np.mean(update_times):.6f} s, Var = {np.var(update_times):.6e} s^2\")\n",
    "\n",
    "    return np.asarray(its), np.asarray(ts), np.asarray([evaluate(x_i).item() for x_i in trace]), np.asarray(comp_times), np.asarray(update_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.43\n",
    "its_single, ts_single, losses_single, comp_single, update_single = run_single_worker_sgd(\n",
    "    objective_fn=least_squares_objective, \n",
    "    A=A, \n",
    "    b=b,\n",
    "    lr=0.43,\n",
    "    iterations=iterations*num_workers,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "f_min_val = f_min.item()\n",
    "plt.yscale('log')\n",
    "plt.plot(its_single, losses_single - f_min_val, label='Single-worker SGD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5af43f",
   "metadata": {},
   "source": [
    "### cpu versipn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391303a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_npy = rng.uniform(size=(n_data, dim)) / np.sqrt(dim)\n",
    "# x_rand_npy = rng.normal(size=dim)\n",
    "# b_npy = A_npy @ x_rand_npy + noise_scale * rng.normal(size=n_data)\n",
    "\n",
    "# def batch_grad_func(rng, x, batch_size):\n",
    "#     idx = rng.choice(n_data, size=batch_size, replace=False)\n",
    "#     return (A_npy[idx]@x - b_npy[idx]) @ A_npy[idx] / batch_size\n",
    "\n",
    "# def evaluate_npy(x):\n",
    "#     assert len(x) == dim\n",
    "#     return 0.5 * np.mean((A_npy @ x - b_npy)**2)\n",
    "\n",
    "# def run_single_worker_sgd(lr, iterations, batch_size):\n",
    "#     \"\"\"\n",
    "#     Runs a single-worker (pure) minibatch SGD.\n",
    "#     \"\"\"\n",
    "#     # rng = np.random.default_rng(42)\n",
    "#     x = np.zeros(dim)\n",
    "    \n",
    "#     trace = []\n",
    "#     its = []\n",
    "#     ts = []\n",
    "#     t0 = time.perf_counter()\n",
    "    \n",
    "#     for it in range(iterations):\n",
    "#         # Calculate gradient on a large batch\n",
    "#         grad = batch_grad_func(rng, x, batch_size)\n",
    "        \n",
    "#         # Update model\n",
    "#         x -= lr * grad\n",
    "        \n",
    "#         if it % it_check == 0:\n",
    "#             trace.append(x.copy())\n",
    "#             its.append(it)\n",
    "#             ts.append(time.perf_counter() - t0)\n",
    "            \n",
    "#     return np.asarray(its), np.asarray(ts), np.asarray([evaluate_npy(x) for x in trace])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.43\n",
    "# iterations_single = iterations * num_workers\n",
    "# its_single, ts_single, losses_single = run_single_worker_sgd(\n",
    "#     lr=0.43,\n",
    "#     iterations=iterations_single,\n",
    "#     batch_size=batch_size\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_opt, _, _, _ = np.linalg.lstsq(A_npy, b_npy)\n",
    "# f_min = evaluate_npy(x_opt)\n",
    "# plt.yscale('log')\n",
    "# plt.plot(its_single, losses_single - f_min, label='Single-worker SGD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8c9ba1",
   "metadata": {},
   "source": [
    "## Distributed-SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0008fc2d",
   "metadata": {},
   "source": [
    "## Distributed Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663588b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class ParameterServer(object):\n",
    "    \"\"\"\n",
    "    Parameter server for asynchronous and synchronous SGD.\n",
    "    Arguments:\n",
    "        lr (float): the stepsize to be used at initialization\n",
    "        asynchronous (bool): if True, use asynchronous SGD; if False, use synchronous SGD\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr, asynchronous, num_workers=0, async_cached=False):\n",
    "        self.x = torch.zeros(dim, 1, requires_grad=True)\n",
    "        self.lr = lr\n",
    "        self.asynchronous = asynchronous\n",
    "        if async_cached:\n",
    "            # Initialize with Tensors to avoid TypeError in torch.stack\n",
    "            self.gradient_cache = [torch.zeros(dim, 1) for _ in range(num_workers)]\n",
    "        else:\n",
    "            self.gradient_cache = None\n",
    "        \n",
    "        self.update_times = []\n",
    "\n",
    "    def apply_gradients(self, grad, *gradients):\n",
    "        t_start = time.perf_counter()\n",
    "        # *可以把一串位置参数打包到一个元组里\n",
    "        if self.asynchronous:\n",
    "                with torch.no_grad():\n",
    "                    self.x -= self.lr * grad\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                summed_gradients = torch.sum(torch.stack(gradients), dim=0)\n",
    "                self.x -= self.lr * summed_gradients\n",
    "        \n",
    "        t_end = time.perf_counter()\n",
    "        self.update_times.append(t_end - t_start)\n",
    "        return self.x\n",
    "    \n",
    "    def apply_cached_gradients(self, worker_id, grad):\n",
    "        t_start = time.perf_counter()\n",
    "        # Ensure incoming grad is a Tensor (handle potential numpy conversion by Ray)\n",
    "        if isinstance(grad, np.ndarray):\n",
    "            grad = torch.from_numpy(grad).float()\n",
    "            \n",
    "        self.gradient_cache[worker_id] = grad\n",
    "        summed_gradients = torch.sum(torch.stack(self.gradient_cache), dim=0)\n",
    "        \n",
    "        # Use .data to update parameters to avoid autograd issues with in-place operations on leaf variables\n",
    "        with torch.no_grad():\n",
    "            self.x -= self.lr * summed_gradients\n",
    "        \n",
    "        t_end = time.perf_counter()\n",
    "        self.update_times.append(t_end - t_start)\n",
    "        return self.x\n",
    "\n",
    "    def get_x(self):\n",
    "        return self.x\n",
    "    \n",
    "    def update_lr(self, lr_new=None):\n",
    "        if lr_new is not None:\n",
    "            self.lr = lr_new\n",
    "        \n",
    "    def get_hyperparams(self):\n",
    "        return self.lr, self.asynchronous\n",
    "    \n",
    "    def get_update_times(self):\n",
    "        return self.update_times\n",
    "    \n",
    "    \n",
    "@ray.remote\n",
    "class DataWorker(object):\n",
    "    \"\"\"\n",
    "    The class for an individual Ray worker.\n",
    "    Arguments:\n",
    "        objective_fn (callable): the objective function to compute loss\n",
    "        A_shard (np.ndarray or torch.Tensor): a shard of the data matrix A\n",
    "        b_shard (np.ndarray or torch.Tensor): a shard of the data vector b\n",
    "        lr (float): the stepsize to be used at initialization\n",
    "        batch_size (int, optional): batch size for sampling gradients (default: 1)\n",
    "        seed (int, optional): random seed to generate random variables for reproducibility (default: 0)\n",
    "    \"\"\"\n",
    "    def __init__(self, objective_fn, A_shard, b_shard, lr, batch_size=1, seed=0):\n",
    "        # runtime checks\n",
    "        if not callable(objective_fn):\n",
    "            raise TypeError(\"objective_fn must be callable and accept (A_in, b_in, x) -> scalar torch.Tensor\")\n",
    "\n",
    "        self.A = A_shard\n",
    "        self.b = b_shard\n",
    "        self.n_data = A_shard.shape[0]\n",
    "        self.lr = lr\n",
    "        self.objective_fn = objective_fn\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Ensure seed is an int and create a local Generator so each worker is independent.\n",
    "        self.seed = int(seed)\n",
    "        self.rng = np.random.default_rng(self.seed)\n",
    "\n",
    "    def compute_gradients(self, x):\n",
    "        t_start = time.perf_counter()\n",
    "        # x.requires_grad = True\n",
    "        x.grad= None\n",
    "            \n",
    "        # t0 = time.perf_counter()\n",
    "        if self.batch_size is None:\n",
    "            # Full gradient\n",
    "            loss = self.objective_fn(self.A, self.b, x)\n",
    "            loss.backward()\n",
    "            grad = x.grad\n",
    "        elif self.batch_size == 1:\n",
    "            # Stochastic gradient\n",
    "            i = int(self.rng.integers(self.n_data))\n",
    "            loss = self.objective_fn(self.A[i], self.b[i], x)\n",
    "            loss.backward()\n",
    "            grad = x.grad\n",
    "        else:\n",
    "            # M-sync gradient\n",
    "            idx = self.rng.choice(self.n_data, size=self.batch_size, replace=False)\n",
    "            loss = self.objective_fn(self.A[idx], self.b[idx], x)\n",
    "            loss.backward()\n",
    "            grad = x.grad\n",
    "            \n",
    "        t_end = time.perf_counter()\n",
    "        # Return grad, computation duration, and end timestamp\n",
    "        return grad, t_end - t_start, t_end\n",
    "\n",
    "        \n",
    "    def get_hyperparams(self):\n",
    "        return self.lr, self.batch_size\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return self.lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c1cfb",
   "metadata": {},
   "source": [
    "## Distributed Algriothms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5212ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(num_workers, lr, iterations=200, asynchronous=True, delay_adaptive=False,\n",
    "        batch_size=1, objective_fn=least_squares_objective,async_cached=False, seed=42):\n",
    "    \"\"\"Run the distributed training.\n",
    "\n",
    "    seed: int -- used to initialize the NumPy Generator that creates per-worker seeds.\n",
    "    \"\"\"\n",
    "    worker_updates = [0 for i in range(num_workers)]\n",
    "    rng = np.random.default_rng(seed)\n",
    "    seeds_workers = rng.choice(max_seed, size=num_workers, replace=False)\n",
    "    #seeds_workers = [rng.choice(max_seed, size=1, replace=False)[0] for _ in range(num_workers)]\n",
    "\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "    \n",
    "    # Partition the data and put it in the object store.\n",
    "    A_shards = torch.chunk(A, num_workers)\n",
    "    b_shards = torch.chunk(b, num_workers)\n",
    "    A_shard_refs = [ray.put(shard) for shard in A_shards]\n",
    "    b_shard_refs = [ray.put(shard) for shard in b_shards]\n",
    "\n",
    "    # ps = ParameterServer.remote(lr, asynchronous)\n",
    "    ps = ParameterServer.remote(lr, asynchronous, num_workers, async_cached=async_cached)\n",
    "    # Ensure argument order matches DataWorker.__init__(objective_fn, A_shard, b_shard, lr, ...)\n",
    "    workers = [DataWorker.remote(objective_fn,\n",
    "                                 A_shard_refs[i], \n",
    "                                 b_shard_refs[i],\n",
    "                                 lr=lr, \n",
    "                                 batch_size=batch_size, \n",
    "                                 seed=int(seeds_workers[i])) for i in range(num_workers)]\n",
    "\n",
    "    x = ps.get_x.remote()\n",
    "    \n",
    "    # Stats collection\n",
    "    comp_times = []\n",
    "    comm_times = []\n",
    "    stats_history = [] # List of dicts: {'worker_id': int, 'comp_time': float, 'comm_time': float, 'it': int}\n",
    "    \n",
    "    if asynchronous:\n",
    "        gradients = {}\n",
    "        worker_last_it = [0 for _ in range(num_workers)]\n",
    "        worker_id_to_num = {}\n",
    "        for e, worker in enumerate(workers):\n",
    "            # Store start time\n",
    "            t_start = time.perf_counter() #########################################################这里后续还可以做更改\n",
    "            gradients[worker.compute_gradients.remote(x)] = (worker, t_start)\n",
    "            worker_id_to_num[worker] = e\n",
    "\n",
    "\n",
    "    its = []\n",
    "    ts = []\n",
    "    delays = []\n",
    "    delay = 0\n",
    "    trace = []\n",
    "    # grads_per_it = 1 if asynchronous else num_workers\n",
    "    t0 = time.perf_counter()\n",
    "    for it in range(iterations * (num_workers if asynchronous else 1)):\n",
    "        # n_grads = it * grads_per_it # 异步时n_grads = it；同步时n_grads = it * num_workers\n",
    "        if asynchronous:\n",
    "            ready_gradient_list, _ = ray.wait(list(gradients),num_returns=1) #ray.wait作用在任务句柄的列表上，返回已经完成的任务句柄列表和未完成的任务句柄列表，只返回一个已经完成的任务句柄。\n",
    "            ready_gradient_id = ready_gradient_list[0]\n",
    "            t_now = time.perf_counter() # Capture arrival time at server\n",
    "            \n",
    "            worker, t_task_start = gradients.pop(ready_gradient_id) #从字典 gradients 中，删除并返回 key 为 ready_gradient_id 的那个 value（也就是对应的 worker 对象 和 t_start\n",
    "            worker_num = worker_id_to_num[worker]\n",
    "            \n",
    "            # Get result and measure time\n",
    "            grad_tuple = ray.get(ready_gradient_id) # 获取已经计算完成的梯度值\n",
    "            grad, t_comp, t_worker_end = grad_tuple\n",
    "            \n",
    "            comm_time = t_now - t_worker_end\n",
    "            comp_times.append(t_comp)\n",
    "            comm_times.append(comm_time)\n",
    "            stats_history.append({'worker_id': worker_num, 'comp_time': t_comp, 'comm_time': comm_time, 'it': it})\n",
    "\n",
    "            # Compute and apply gradients.\n",
    "            # t_next_start = time.perf_counter()\n",
    "            # gradients[worker.compute_gradients.remote(x)] = (worker, t_next_start) # 重新计算该 worker 的梯度，并将新的任务句柄存回 gradients 字典\n",
    "            \n",
    "            delay = it - worker_last_it[worker_num] # 计算该 worker 的延迟\n",
    "\n",
    "            if delay_adaptive:\n",
    "                lr_new = lr * num_workers / max(num_workers, delay)\n",
    "                ps.update_lr.remote(lr_new=lr_new)\n",
    "            if async_cached:\n",
    "                x = ps.apply_cached_gradients.remote(worker_num, grad)\n",
    "            else:\n",
    "                x = ps.apply_gradients.remote(grad) # 针对已经计算完成的梯度进行参数更新\n",
    "\n",
    "            \n",
    "            t_next_start = time.perf_counter()\n",
    "            gradients[worker.compute_gradients.remote(x)] = (worker, t_next_start) # 重新计算该 worker 的梯度，并将新的任务句柄存回 gradients 字典\n",
    "\n",
    "            worker_last_it[worker_num] = it\n",
    "            worker_updates[worker_num] += 1\n",
    "        else:\n",
    "            # Synchronous\n",
    "            gradients = [worker.compute_gradients.remote(x) for worker in workers]\n",
    "            ref_to_worker_id = {gradients[i]: i for i in range(len(workers))}\n",
    "            \n",
    "            pending = gradients[:]\n",
    "            batch_grads = []\n",
    "            \n",
    "            # Collect all gradients, measuring arrival time for each\n",
    "            while pending:\n",
    "                ready_list, pending = ray.wait(pending, num_returns=1)\n",
    "                t_now = time.perf_counter()\n",
    "                for obj_id in ready_list:\n",
    "                    grad, t_comp, t_worker_end = ray.get(obj_id)\n",
    "                    w_id = ref_to_worker_id[obj_id]\n",
    "                    \n",
    "                    comm_time = t_now - t_worker_end\n",
    "                    comp_times.append(t_comp)\n",
    "                    comm_times.append(comm_time)\n",
    "                    stats_history.append({'worker_id': w_id, 'comp_time': t_comp, 'comm_time': comm_time, 'it': it})\n",
    "                    \n",
    "                    batch_grads.append(grad)\n",
    "            \n",
    "            x = ps.apply_gradients.remote(None, *batch_grads)\n",
    "\n",
    "        # if (asynchronous and not async_cached and it % it_check == 0):\n",
    "\n",
    "        if (asynchronous and it % it_check == 0):\n",
    "            # Evaluate the current model.\n",
    "            x_val = ray.get(ps.get_x.remote())\n",
    "            trace.append(x_val.clone().detach())\n",
    "            its.append(it)\n",
    "            ts.append(time.perf_counter() - t0)\n",
    "        else:\n",
    "            if not asynchronous:\n",
    "                # Evaluate the current model.\n",
    "                x_val = ray.get(ps.get_x.remote())\n",
    "                trace.append(x_val.clone().detach())\n",
    "                its.append(it*num_workers)\n",
    "                ts.append(time.perf_counter() - t0)\n",
    "\n",
    "\n",
    "        t = time.perf_counter()\n",
    "        if asynchronous:\n",
    "            delays.append(delay)\n",
    "\n",
    "    # Fetch update times from PS\n",
    "    update_times = ray.get(ps.get_update_times.remote())\n",
    "    \n",
    "    print(f\"Run Stats (Async={asynchronous}, Cached={async_cached}, Adaptive={delay_adaptive}):\")\n",
    "    print(f\"  Gradient Computation: Mean = {np.mean(comp_times):.6f} s, Var = {np.var(comp_times):.6e} s^2\")\n",
    "    print(f\"  Parameter Update:     Mean = {np.mean(update_times):.6f} s, Var = {np.var(update_times):.6e} s^2\")\n",
    "    print(f\"  Communication:        Mean = {np.mean(comm_times):.6f} s, Var = {np.var(comm_times):.6e} s^2\")\n",
    "\n",
    "    ray.shutdown()\n",
    "    return np.asarray(its), np.asarray(ts), np.asarray([evaluate(x) for x in trace]), np.asarray(delays), np.asarray(comp_times), np.asarray(update_times), np.asarray(comm_times), stats_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe8341-7c14-42c5-9f54-b99cb066e9a1",
   "metadata": {},
   "source": [
    "### Synchronous Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_asc = 0.001 # best tuned\n",
    "its_asc, ts_asc, losses_asc, delays, comp_asc, update_asc, comm_asc, stats_asc = run(num_workers, lr=lr_asc,\n",
    "                                 iterations=iterations,\n",
    "                                 asynchronous=True,\n",
    "                                 delay_adaptive=False,\n",
    "                                 batch_size=batch_size// num_workers,\n",
    "                                 async_cached=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47adbfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mini = 0.19 # best tuned\n",
    "its_, ts_, losses_, delays, comp_sync, update_sync, comm_sync, stats_sync = run(num_workers, lr=lr_mini,\n",
    "                                 iterations=iterations,\n",
    "                                 asynchronous=False,\n",
    "                                 delay_adaptive=False,\n",
    "                                 batch_size=batch_size// num_workers,\n",
    "                                 async_cached=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1138ce1",
   "metadata": {},
   "source": [
    "### Asynchronous Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4170a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_as = 0.43 # best tuned\n",
    "its_as, ts_as, losses_as, delays, comp_as, update_as, comm_as, stats_as = run(num_workers, lr=lr_as,\n",
    "                                       iterations=iterations,\n",
    "                                       asynchronous=True,\n",
    "                                       delay_adaptive=False,\n",
    "                                       batch_size=batch_size,\n",
    "                                       async_cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a98c99-8420-456c-a910-92dd8cc64d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ad = 0.43 # best tuned\n",
    "its_ad, ts_ad, losses_ad, delays, comp_ad, update_ad, comm_ad, stats_ad = run(num_workers, lr=lr_ad,\n",
    "                                       iterations=iterations,\n",
    "                                       asynchronous=True,\n",
    "                                       delay_adaptive=True,\n",
    "                                       batch_size=batch_size,\n",
    "                                       async_cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e3352-476f-460e-bf33-9fd1c3c216e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(its_ * it_check, losses_ - f_min_val, label='M-sync SGD')\n",
    "plt.plot(its_asc * it_check, losses_asc - f_min_val, label='Async Cached SGD')\n",
    "plt.plot(its_as * it_check, losses_as - f_min_val, label='Asynchronous SGD')\n",
    "plt.plot(its_ad * it_check, losses_ad - f_min_val, label='Delay-Adaptive AsySGD')\n",
    "plt.plot(its_single, losses_single - f_min_val, label='Mini-batch SGD')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of gradients')\n",
    "plt.ylabel(r'$F(\\mathbf{x}) - F^*$')\n",
    "# plt.savefig(f'quadratic_grads_M_{num_workers}_n={n_data}_dim={dim}_bs_{batch_size}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bffccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts_ , losses_ - f_min_val, label='M-sync SGD')\n",
    "plt.plot(ts_asc, losses_asc - f_min_val, label='Async Cached SGD')\n",
    "plt.plot(ts_as, losses_as - f_min_val, label='Asynchronous SGD')\n",
    "plt.plot(ts_ad, losses_ad - f_min_val, label='Delay-Adaptive AsySGD')\n",
    "plt.plot(ts_single, losses_single - f_min_val, label='Mini-batch SGD')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel(r'$F(\\mathbf{x}) - F^*$')\n",
    "# plt.savefig(f'quadratic_grads_M_{num_workers}_n={n_data}_dim={dim}_bs_{batch_size}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc2ab7-aa81-4760-9e76-e8577836beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# delay 直方图\n",
    "plt.hist(delays, bins=300, color=\"#CEC6C6\", alpha=0.75)\n",
    "plt.yscale('log')\n",
    "\n",
    "# 统计量\n",
    "mean_delay = np.mean(delays)\n",
    "median_delay = np.median(delays)\n",
    "max_delay = np.max(delays)\n",
    "\n",
    "plt.axvline(mean_delay, color=\"#f08843\", linestyle='--', linewidth=4, label=f'Mean = {mean_delay:.1f}')\n",
    "plt.axvline(median_delay, color=\"#4bdbc8\", linestyle=':', linewidth=4, label=f'Median = {median_delay:.1f}')\n",
    "plt.axvline(num_workers, color=\"#46a5ee\", linestyle='-', linewidth=2, label=f'M = {num_workers}')\n",
    "plt.axvline(max_delay, color=\"#f1315a\", linestyle='-.', linewidth=4, label=f'Max = {max_delay:.0f}')\n",
    "plt.grid(False)\n",
    "plt.xlabel('Delay')\n",
    "plt.ylabel('Count (log scale)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Time Distributions\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare data for plotting\n",
    "data = []\n",
    "\n",
    "# Helper to add data\n",
    "def add_data(alg_name, comp, update, comm=None):\n",
    "    for v in comp:\n",
    "        data.append({'Algorithm': alg_name, 'Type': 'Computation', 'Time (s)': v})\n",
    "    for v in update:\n",
    "        data.append({'Algorithm': alg_name, 'Type': 'Update', 'Time (s)': v})\n",
    "    if comm is not None:\n",
    "        for v in comm:\n",
    "            data.append({'Algorithm': alg_name, 'Type': 'Communication', 'Time (s)': v})\n",
    "\n",
    "add_data('Single-worker', comp_single, update_single)\n",
    "add_data('M-sync SGD', comp_sync, update_sync, comm_sync)\n",
    "add_data('Async Cached', comp_asc, update_asc, comm_asc)\n",
    "add_data('Asynchronous', comp_as, update_as, comm_as)\n",
    "add_data('Delay-Adaptive', comp_ad, update_ad, comm_ad)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(x='Algorithm', y='Time (s)', hue='Type', data=df, showfliers=False) # showfliers=False to hide outliers for better scale\n",
    "plt.title('Distribution of Time Components across Algorithms')\n",
    "plt.yscale('log') # Log scale to see small values (like updates) and large values (like comms) together\n",
    "plt.ylabel('Time (seconds) - Log Scale')\n",
    "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "plt.legend(title='Component')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Separate plots for clearer view if scales are too different\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "sns.boxplot(x='Algorithm', y='Time (s)', data=df[df['Type']=='Computation'], ax=axes[0], showfliers=False)\n",
    "axes[0].set_title('Gradient Computation Time')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "sns.boxplot(x='Algorithm', y='Time (s)', data=df[df['Type']=='Update'], ax=axes[1], showfliers=False)\n",
    "axes[1].set_title('Parameter Update Time')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45)\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "sns.boxplot(x='Algorithm', y='Time (s)', data=df[df['Type']=='Communication'], ax=axes[2], showfliers=False)\n",
    "axes[2].set_title('Communication Time')\n",
    "axes[2].set_xticklabels(axes[2].get_xticklabels(), rotation=45)\n",
    "axes[2].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825960fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Communication Time per Worker\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Helper to prepare dataframe for per-worker stats\n",
    "def get_worker_comm_df(stats_list, alg_name):\n",
    "    rows = []\n",
    "    for item in stats_list:\n",
    "        rows.append({\n",
    "            'Worker ID': item['worker_id'],\n",
    "            'Communication Time (s)': item['comm_time'],\n",
    "            'Algorithm': alg_name\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_sync = get_worker_comm_df(stats_sync, 'M-sync SGD')\n",
    "df_async = get_worker_comm_df(stats_as, 'Asynchronous SGD')\n",
    "df_async_cached = get_worker_comm_df(stats_asc, 'Async Cached SGD')\n",
    "df_adaptive = get_worker_comm_df(stats_ad, 'Delay-Adaptive AsySGD')\n",
    "\n",
    "# Combine all (or select one to view)\n",
    "# Let's plot Asynchronous SGD as it's the most relevant for per-worker variance\n",
    "df_all_workers = pd.concat([df_sync, df_async, df_async_cached, df_adaptive])\n",
    "\n",
    "# Plotting Asynchronous SGD specifically first\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.boxplot(x='Worker ID', y='Communication Time (s)', data=df_async, color='skyblue', showfliers=False)\n",
    "plt.title('Communication Time per Worker (Asynchronous SGD)')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Plotting M-sync SGD\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.boxplot(x='Worker ID', y='Communication Time (s)', data=df_sync, color='lightgreen', showfliers=False)\n",
    "plt.title('Communication Time per Worker (M-sync SGD)')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Heatmap of communication time over iterations for one algorithm\n",
    "plt.figure(figsize=(18, 6))\n",
    "# Pivot data for heatmap: Index=Iteration, Columns=Worker ID, Values=Comm Time\n",
    "# Note: For Async, not all workers update in every \"iteration\" of the main loop in the same way, \n",
    "# but we recorded 'it' in stats.\n",
    "# Let's just take the first 100 updates for each worker to visualize\n",
    "df_async_subset = df_async.groupby('Worker ID').head(50).copy()\n",
    "df_async_subset['Update Index'] = df_async_subset.groupby('Worker ID').cumcount()\n",
    "pivot_table = df_async_subset.pivot(index='Worker ID', columns='Update Index', values='Communication Time (s)')\n",
    "\n",
    "sns.heatmap(pivot_table, cmap=\"YlGnBu\", norm=matplotlib.colors.LogNorm())\n",
    "plt.title('Heatmap of Communication Time (First 50 updates per worker) - Asynchronous SGD')\n",
    "plt.xlabel('Update Number (per worker)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b29602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# batch_sizes_to_test = [8, 16, 32, 64, 128]\n",
    "# results = {}\n",
    "\n",
    "# # 为所有批处理大小使用相同的预设学习率，以便进行统一比较。\n",
    "# # 同步算法的学习率设置为0.19，异步算法为0.43。\n",
    "# lr_sync = 0.19\n",
    "# lr_async = 0.43\n",
    "# f_min_val = f_min.item()\n",
    "\n",
    "# for bs in batch_sizes_to_test:\n",
    "#     print(f\"--- Running for batch_size = {bs} ---\")\n",
    "    \n",
    "#     # (M-sync SGD)\n",
    "#     print(\"Running Synchronous SGD...\")\n",
    "#     its_sync, ts_sync, losses_sync, _ = run(\n",
    "#         num_workers, lr=lr_sync, iterations=iterations, \n",
    "#         asynchronous=False, delay_adaptive=False, batch_size=bs\n",
    "#     )\n",
    "    \n",
    "#     # 异步算法\n",
    "#     print(\"Running Asynchronous SGD...\")\n",
    "#     its_async, ts_async, losses_async, _ = run(\n",
    "#         num_workers, lr=lr_async, iterations=iterations, \n",
    "#         asynchronous=True, delay_adaptive=False, batch_size=bs\n",
    "#     )\n",
    "    \n",
    "#     # 自适应异步算法\n",
    "#     print(\"Running Delay-Adaptive Asynchronous SGD...\")\n",
    "#     its_ad, ts_ad, losses_ad, delays_ad = run(\n",
    "#         num_workers, lr=lr_async, iterations=iterations, \n",
    "#         asynchronous=True, delay_adaptive=True, batch_size=bs\n",
    "#     )\n",
    "    \n",
    "#     results[bs] = {\n",
    "#         'sync': {'ts': ts_sync, 'losses': losses_sync},\n",
    "#         'async': {'ts': ts_async, 'losses': losses_async},\n",
    "#         'adaptive': {'ts': ts_ad, 'losses': losses_ad},\n",
    "#     }\n",
    "#     print(f\"--- Finished for batch_size = {bs} ---\\n\")\n",
    "\n",
    "# # 对比图\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(27, 8), sharey=True)\n",
    "# fig.suptitle('Comparison of Algorithms for Different Batch Sizes', fontsize=20)\n",
    "\n",
    "# # (M-sync SGD)\n",
    "# ax1 = axes[0]\n",
    "# for bs in batch_sizes_to_test:\n",
    "#     res = results[bs]['sync']\n",
    "#     ax1.plot(res['ts'], res['losses'] - f_min_val, label=f'Batch Size = {bs}')\n",
    "# ax1.set_title('Synchronous SGD')\n",
    "# ax1.set_xlabel('Time (seconds)')\n",
    "# ax1.set_ylabel(r'$F(\\mathbf{x}) - F^*$')\n",
    "# ax1.set_yscale('log')\n",
    "# ax1.legend()\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # (Asynchronous SGD)\n",
    "# ax2 = axes[1]\n",
    "# for bs in batch_sizes_to_test:\n",
    "#     res = results[bs]['async']\n",
    "#     ax2.plot(res['ts'], res['losses'] - f_min_val, label=f'Batch Size = {bs}')\n",
    "# ax2.set_title('Asynchronous SGD')\n",
    "# ax2.set_xlabel('Time (seconds)')\n",
    "# ax2.set_yscale('log')\n",
    "# ax2.legend()\n",
    "# ax2.grid(True)\n",
    "\n",
    "# # (Delay-Adaptive AsySGD)\n",
    "# ax3 = axes[2]\n",
    "# for bs in batch_sizes_to_test:\n",
    "#     res = results[bs]['adaptive']\n",
    "#     ax3.plot(res['ts'], res['losses'] - f_min_val, label=f'Batch Size = {bs}')\n",
    "# ax3.set_title('Delay-Adaptive AsySGD')\n",
    "# ax3.set_xlabel('Time (seconds)')\n",
    "# ax3.set_yscale('log')\n",
    "# ax3.legend()\n",
    "# ax3.grid(True)\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56515a9e",
   "metadata": {},
   "source": [
    "# ResNet-18 on CIFAR-10 Experiment\n",
    "\n",
    "This section implements the distributed training of ResNet-18 on CIFAR-10 using the same asynchronous SGD framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5cb44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# CIFAR-10 Data Preparation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Download dataset (if not present)\n",
    "# We assume data folder exists as per workspace info\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Split indices for workers\n",
    "indices = np.arange(len(trainset))\n",
    "rng_data = np.random.default_rng(42)\n",
    "rng_data.shuffle(indices)\n",
    "worker_indices = np.array_split(indices, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489a9419",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class DLParameterServer(object):\n",
    "    def __init__(self, model_creator, lr, asynchronous, num_workers=0, async_cached=False):\n",
    "        self.model = model_creator()\n",
    "        self.model.train()\n",
    "        # Use SGD optimizer\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "        \n",
    "        self.asynchronous = asynchronous\n",
    "        self.update_times = []\n",
    "        \n",
    "        # For async_cached, we need to cache gradients. \n",
    "        if async_cached:\n",
    "            # Initialize cache with zeros matching model parameters\n",
    "            self.gradient_cache = {\n",
    "                i: [torch.zeros_like(p) for p in self.model.parameters()] \n",
    "                for i in range(num_workers)\n",
    "            }\n",
    "        else:\n",
    "            self.gradient_cache = None\n",
    "\n",
    "    def apply_gradients(self, grad_list, *other_grad_lists):\n",
    "        t_start = time.perf_counter()\n",
    "        \n",
    "        if self.asynchronous:\n",
    "            # Apply single gradient\n",
    "            self.optimizer.zero_grad()\n",
    "            for p, g in zip(self.model.parameters(), grad_list):\n",
    "                if g is not None:\n",
    "                    p.grad = g\n",
    "            self.optimizer.step()\n",
    "        else:\n",
    "            # Synchronous: Sum gradients\n",
    "            all_grads = [g for g in [grad_list] + list(other_grad_lists) if g is not None]\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Sum gradients\n",
    "            for i, p in enumerate(self.model.parameters()):\n",
    "                # Stack gradients for this parameter from all workers and sum\n",
    "                p_grads = [g_list[i] for g_list in all_grads if g_list[i] is not None]\n",
    "                if p_grads:\n",
    "                    p.grad = torch.sum(torch.stack(p_grads), dim=0)\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "        t_end = time.perf_counter()\n",
    "        self.update_times.append(t_end - t_start)\n",
    "        return self.get_weights()\n",
    "\n",
    "    def apply_cached_gradients(self, worker_id, grad_list):\n",
    "        t_start = time.perf_counter()\n",
    "        \n",
    "        # Update cache for this worker\n",
    "        self.gradient_cache[worker_id] = grad_list\n",
    "        \n",
    "        # Sum all cached gradients\n",
    "        self.optimizer.zero_grad()\n",
    "        for i, p in enumerate(self.model.parameters()):\n",
    "            # Sum across all workers for parameter i\n",
    "            p_grads = [self.gradient_cache[w_id][i] for w_id in self.gradient_cache if self.gradient_cache[w_id][i] is not None]\n",
    "            if p_grads:\n",
    "                p.grad = torch.sum(torch.stack(p_grads), dim=0)\n",
    "            \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        t_end = time.perf_counter()\n",
    "        self.update_times.append(t_end - t_start)\n",
    "        return self.get_weights()\n",
    "\n",
    "    def get_weights(self):\n",
    "        # Return state_dict. Move to CPU to ensure pickling works well.\n",
    "        return {k: v.cpu() for k, v in self.model.state_dict().items()}\n",
    "    \n",
    "    def update_lr(self, lr_new=None):\n",
    "        if lr_new is not None:\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] = lr_new\n",
    "\n",
    "    def get_update_times(self):\n",
    "        return self.update_times\n",
    "    \n",
    "    def get_model(self):\n",
    "        # Helper to get model for evaluation (though we usually eval on local copy)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daf401c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class DLWorker(object):\n",
    "    def __init__(self, model_creator, data_indices, lr, batch_size=32, seed=0):\n",
    "        # Re-define transforms here to ensure they are available in worker process\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        \n",
    "        self.trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform_train)\n",
    "        self.indices = data_indices\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = int(seed)\n",
    "        self.rng = np.random.default_rng(self.seed)\n",
    "        \n",
    "        # Local model\n",
    "        self.model = model_creator()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def compute_gradients(self, weights):\n",
    "        t_start = time.perf_counter()\n",
    "        \n",
    "        # Load weights\n",
    "        self.model.load_state_dict(weights)\n",
    "        self.model.train()\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Sample batch\n",
    "        batch_indices = self.rng.choice(self.indices, size=self.batch_size, replace=False)\n",
    "        \n",
    "        inputs = []\n",
    "        targets = []\n",
    "        for idx in batch_indices:\n",
    "            img, target = self.trainset[idx]\n",
    "            inputs.append(img)\n",
    "            targets.append(target)\n",
    "            \n",
    "        inputs = torch.stack(inputs)\n",
    "        targets = torch.tensor(targets)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # Get gradients\n",
    "        grads = [p.grad.cpu() if p.grad is not None else torch.zeros_like(p).cpu() for p in self.model.parameters()]\n",
    "        \n",
    "        t_end = time.perf_counter()\n",
    "        return grads, t_end - t_start, t_end\n",
    "    \n",
    "    def get_hyperparams(self):\n",
    "        return self.lr, self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4c4b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dl(model_creator, weights):\n",
    "    model = model_creator()\n",
    "    model.load_state_dict(weights)\n",
    "    model.eval()\n",
    "    \n",
    "    # Use a smaller batch size for evaluation to avoid OOM if running on CPU\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=0)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_sum += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    return loss_sum / total, 100 * correct / total\n",
    "\n",
    "def run_dl(model_creator, num_workers, lr, iterations=200, asynchronous=True, delay_adaptive=False,\n",
    "        batch_size=32, async_cached=False, seed=42):\n",
    "    \n",
    "    worker_updates = [0 for i in range(num_workers)]\n",
    "    rng = np.random.default_rng(seed)\n",
    "    seeds_workers = rng.choice(max_seed, size=num_workers, replace=False)\n",
    "\n",
    "    # ray.init(ignore_reinit_error=True) # Already initialized\n",
    "    \n",
    "    ps = DLParameterServer.remote(model_creator, lr, asynchronous, num_workers, async_cached=async_cached)\n",
    "    \n",
    "    workers = [DLWorker.remote(model_creator, worker_indices[i],\n",
    "                                 lr=lr, \n",
    "                                 batch_size=batch_size, \n",
    "                                 seed=int(seeds_workers[i])) for i in range(num_workers)]\n",
    "\n",
    "    weights = ps.get_weights.remote()\n",
    "    \n",
    "    # Stats collection\n",
    "    comp_times = []\n",
    "    comm_times = []\n",
    "    stats_history = [] \n",
    "    \n",
    "    if asynchronous:\n",
    "        gradients = {}\n",
    "        worker_last_it = [0 for _ in range(num_workers)]\n",
    "        worker_id_to_num = {}\n",
    "        for e, worker in enumerate(workers):\n",
    "            t_start = time.perf_counter()\n",
    "            gradients[worker.compute_gradients.remote(weights)] = (worker, t_start)\n",
    "            worker_id_to_num[worker] = e\n",
    "\n",
    "    its = []\n",
    "    ts = []\n",
    "    delays = []\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    \n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "    # Total updates = iterations * num_workers (if async)\n",
    "    total_updates = iterations * (num_workers if asynchronous else 1)\n",
    "    \n",
    "    for it in range(total_updates):\n",
    "        if asynchronous:\n",
    "            ready_gradient_list, _ = ray.wait(list(gradients), num_returns=1)\n",
    "            ready_gradient_id = ready_gradient_list[0]\n",
    "            t_now = time.perf_counter()\n",
    "            \n",
    "            worker, t_task_start = gradients.pop(ready_gradient_id)\n",
    "            worker_num = worker_id_to_num[worker]\n",
    "            \n",
    "            grad_tuple = ray.get(ready_gradient_id)\n",
    "            grad, t_comp, t_worker_end = grad_tuple\n",
    "            \n",
    "            comm_time = t_now - t_worker_end\n",
    "            comp_times.append(t_comp)\n",
    "            comm_times.append(comm_time)\n",
    "            stats_history.append({'worker_id': worker_num, 'comp_time': t_comp, 'comm_time': comm_time, 'it': it})\n",
    "\n",
    "            delay = it - worker_last_it[worker_num]\n",
    "            delays.append(delay)\n",
    "\n",
    "            if delay_adaptive:\n",
    "                lr_new = lr * num_workers / max(num_workers, delay)\n",
    "                ps.update_lr.remote(lr_new=lr_new)\n",
    "                \n",
    "            if async_cached:\n",
    "                weights = ps.apply_cached_gradients.remote(worker_num, grad)\n",
    "            else:\n",
    "                weights = ps.apply_gradients.remote(grad)\n",
    "\n",
    "            t_next_start = time.perf_counter()\n",
    "            gradients[worker.compute_gradients.remote(weights)] = (worker, t_next_start)\n",
    "\n",
    "            worker_last_it[worker_num] = it\n",
    "            worker_updates[worker_num] += 1\n",
    "        else:\n",
    "            # Synchronous\n",
    "            gradients = [worker.compute_gradients.remote(weights) for worker in workers]\n",
    "            ref_to_worker_id = {gradients[i]: i for i in range(len(workers))}\n",
    "            \n",
    "            pending = gradients[:]\n",
    "            batch_grads = []\n",
    "            \n",
    "            while pending:\n",
    "                ready_list, pending = ray.wait(pending, num_returns=1)\n",
    "                t_now = time.perf_counter()\n",
    "                for obj_id in ready_list:\n",
    "                    grad, t_comp, t_worker_end = ray.get(obj_id)\n",
    "                    w_id = ref_to_worker_id[obj_id]\n",
    "                    \n",
    "                    comm_time = t_now - t_worker_end\n",
    "                    comp_times.append(t_comp)\n",
    "                    comm_times.append(comm_time)\n",
    "                    stats_history.append({'worker_id': w_id, 'comp_time': t_comp, 'comm_time': comm_time, 'it': it})\n",
    "                    \n",
    "                    batch_grads.append(grad)\n",
    "            \n",
    "            weights = ps.apply_gradients.remote(None, *batch_grads)\n",
    "\n",
    "        # Evaluate periodically\n",
    "        if it % it_check == 0:\n",
    "            current_weights = ray.get(weights)\n",
    "            loss_val, acc_val = evaluate_dl(model_creator, current_weights)\n",
    "            \n",
    "            its.append(it)\n",
    "            ts.append(time.perf_counter() - t0)\n",
    "            losses.append(loss_val)\n",
    "            accuracies.append(acc_val)\n",
    "            print(f\"Iter {it}: Loss={loss_val:.4f}, Acc={acc_val:.2f}%\")\n",
    "\n",
    "    update_times = ray.get(ps.get_update_times.remote())\n",
    "    \n",
    "    print(f\"Run Stats (Async={asynchronous}, Cached={async_cached}, Adaptive={delay_adaptive}):\")\n",
    "    print(f\"  Gradient Computation: Mean = {np.mean(comp_times):.6f} s\")\n",
    "    print(f\"  Parameter Update:     Mean = {np.mean(update_times):.6f} s\")\n",
    "    print(f\"  Communication:        Mean = {np.mean(comm_times):.6f} s\")\n",
    "\n",
    "    # ray.shutdown() # Do not shutdown as we might run multiple experiments\n",
    "    return np.asarray(its), np.asarray(ts), np.asarray(losses), np.asarray(accuracies), np.asarray(delays), np.asarray(comp_times), np.asarray(update_times), np.asarray(comm_times), stats_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d8675ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Synchronous SGD (ResNet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 19:30:43,043\tINFO worker.py:2003 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "/home/cipher/miniconda3/envs/async/lib/python3.11/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m resnet_batch_size = \u001b[32m32\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning Synchronous SGD (ResNet)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m its_sync_rn, ts_sync_rn, losses_sync_rn, acc_sync_rn, _, comp_sync_rn, update_sync_rn, comm_sync_rn, stats_sync_rn = \u001b[43mrun_dl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresnet18_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresnet_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresnet_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay_adaptive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresnet_batch_size\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRunning Asynchronous SGD (ResNet)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m its_async_rn, ts_async_rn, losses_async_rn, acc_async_rn, delays_rn, comp_async_rn, update_async_rn, comm_async_rn, stats_async_rn = run_dl(\n\u001b[32m     19\u001b[39m     resnet18_creator,\n\u001b[32m     20\u001b[39m     num_workers, lr=resnet_lr, iterations=resnet_iterations, \n\u001b[32m     21\u001b[39m     asynchronous=\u001b[38;5;28;01mTrue\u001b[39;00m, delay_adaptive=\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size=resnet_batch_size\n\u001b[32m     22\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 112\u001b[39m, in \u001b[36mrun_dl\u001b[39m\u001b[34m(model_creator, num_workers, lr, iterations, asynchronous, delay_adaptive, batch_size, async_cached, seed)\u001b[39m\n\u001b[32m    109\u001b[39m batch_grads = []\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m pending:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     ready_list, pending = \u001b[43mray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m     t_now = time.perf_counter()\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m obj_id \u001b[38;5;129;01min\u001b[39;00m ready_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/async/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:22\u001b[39m, in \u001b[36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mauto_init_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     21\u001b[39m     auto_init_ray()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/async/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:104\u001b[39m, in \u001b[36mclient_mode_hook.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m func.\u001b[34m__name__\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33minit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func.\u001b[34m__name__\u001b[39m)(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/async/lib/python3.11/site-packages/ray/_private/worker.py:3200\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[39m\n\u001b[32m   3198\u001b[39m timeout = timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m10\u001b[39m**\u001b[32m6\u001b[39m\n\u001b[32m   3199\u001b[39m timeout_milliseconds = \u001b[38;5;28mint\u001b[39m(timeout * \u001b[32m1000\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3200\u001b[39m ready_ids, remaining_ids = \u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcore_worker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpython/ray/_raylet.pyx:3441\u001b[39m, in \u001b[36mray._raylet.CoreWorker.wait\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpython/ray/includes/common.pxi:97\u001b[39m, in \u001b[36mray._raylet.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Define the model creator function\n",
    "def resnet18_creator():\n",
    "    return torchvision.models.resnet18(num_classes=10)\n",
    "\n",
    "# Run Experiments\n",
    "resnet_iterations = 50\n",
    "resnet_lr = 0.01\n",
    "resnet_batch_size = 32\n",
    "\n",
    "print(\"Running Synchronous SGD (ResNet)...\")\n",
    "its_sync_rn, ts_sync_rn, losses_sync_rn, acc_sync_rn, _, comp_sync_rn, update_sync_rn, comm_sync_rn, stats_sync_rn = run_dl(\n",
    "    resnet18_creator,\n",
    "    num_workers, lr=resnet_lr, iterations=resnet_iterations, \n",
    "    asynchronous=False, delay_adaptive=False, batch_size=resnet_batch_size\n",
    ")\n",
    "\n",
    "print(\"\\nRunning Asynchronous SGD (ResNet)...\")\n",
    "its_async_rn, ts_async_rn, losses_async_rn, acc_async_rn, delays_rn, comp_async_rn, update_async_rn, comm_async_rn, stats_async_rn = run_dl(\n",
    "    resnet18_creator,\n",
    "    num_workers, lr=resnet_lr, iterations=resnet_iterations, \n",
    "    asynchronous=True, delay_adaptive=False, batch_size=resnet_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(ts_sync_rn, losses_sync_rn, label='Sync SGD')\n",
    "plt.plot(ts_async_rn, losses_async_rn, label='Async SGD')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Test Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss vs Time')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(ts_sync_rn, acc_sync_rn, label='Sync SGD')\n",
    "plt.plot(ts_async_rn, acc_async_rn, label='Async SGD')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Accuracy vs Time')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "async",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
